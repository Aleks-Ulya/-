# 1. Полное задание из методички с вариантом.
Задание 4: Image Segmentation (Сегментация изображений)
Задача: реализовать простую U-Net архитектуру для сегментации изображений.
Требования:
- Encoder-Decoder архитектура
- Skip connections между encoder и decoder
- Dice loss функция

// Что нужно дополнить:
- 1. Слои свёртки и пулинга
- 2. Транспонированные свёртки для upsampling
- 3. Skip connections
- 4. Dice loss и его градиент

# 2. Алгоритм работы НС по блокам. 
### Инициализация
Задаются начальные значения весов и смещений для каждого свёрточного, пуллингового и транспонированного свёрточного слоя энкодера и декодера U‑Net.​
Определяется количество уровней энкодера/декодера, размер фильтров, а также параметры оптимизатора.
### Подготовка данных
Формируется обучающая выборка из пар «изображение – маска сегментации», изображения нормализуются (например, приводятся к диапазону ) и при необходимости изменяются до общего размера.​​
Данные разделяются на обучающую и тестовую (или валидационную) части для последующего контроля качества модели.
### Прямой проход (Forward Pass)
Входные данные проходят последовательно через каждый блок сети, выполняя операции линейных преобразований и активаций. Результат последнего блока становится выходом сети.
### Вычисление ошибки
Рассчитывается разница между ожидаемым результатом и фактическим значением выхода сети (используя выбранную функцию потери).
### Обратное распространение (Backpropagation)
Выполняется обратный проход по всем слоям сети, где с использованием производной Dice‑loss по выходу сети вычисляются градиенты по активациям, а затем по весовым коэффициентам свёрточных, транспонированных и финального слоёв.​ Градиенты последовательно передаются от выходного слоя назад через блоки декодера и энкодера, учитывая операции конкатенации и пулинга, что позволяет корректировать веса с учётом вклада каждого пикселя в итоговую потерю.
### Корректировка весов
Весовые коэффициенты всех обучаемых слоёв обновляются выбранным оптимизатором на основе вычисленных градиентов и заданной скорости обучения.​ После обновления весов сеть становится чуть ближе к решению задачи: предсказанные маски должны лучше совпадать с целевыми.
### Проверка качества
Через несколько итераций или в конце каждой эпохи запускается прямой проход на тестовом/валидационном наборе без обновления весов, и измеряются показатели качества. ​
По динамике метрик и графикам потерь контролируется переобучение и принимается решение об остановке или изменении гиперпараметров обучения.
### Итерация
Повторение шагов 3-7 до достижения требуемого качества или остановочного критерия.
### Архитектура
Класс UNet реализует архитектуру нейросети U‑Net с энкодером, декодером, skip‑соединениями и функцией потерь Dice‑loss.​
Методы класса:

encode(...) — проход входного изображения через энкодер с сохранением промежуточных признаков для skip‑соединений.​

decode(...) — восстановление пространственного разрешения через декодер с использованием транспонированных свёрток и конкатенации со skip‑слоями.​

forward(...) — полный прямой проход сигнала через сеть от изображения к маске.​

dice_loss(...) — вычисление потерь по метрике Dice для оценки качества сегментации.​

Вспомогательные классы: ConvLayer (примитивный свёрточный слой), PoolLayer (max‑pooling), UpConvLayer (транспонированная свёртка для upsampling), которые используются внутри методов encode и decode для построения полной U‑Net. Такие компоненты соответствуют стандартному описанию архитектуры в литературе по сегментации изображений.
# 3. Ответ на контрольный вопрос
### 4. Докажите, что любой NFA может быть преобразован в эквивалентный DFA.
НФС (NFA, nondeterministic finite automaton) — это недетерминированный конечный автомат, в котором переходы между состояниями могут быть неоднозначными: для одного и того же входного символа из одного состояния возможно несколько разных переходов.

ДКА (DFA, deterministic finite automaton), напротив, представляет собой детерминированный конечный автомат: для каждого состояния и каждого возможного входного символа существует ровно один определённый переход в следующее состояние.

Преобразование NFA в эквивалентный ему DFA осуществляется с помощью алгоритма, известного как «построение по подмножествам» (powerset construction). Работа алгоритма состоит из следующих этапов:

Формирование начального состояния DFA. Стартовое состояние нового DFA создаётся как объединение всех начальных состояний исходного NFA, которые достижимы через ε‑переходы (пустые переходы).

Генерация состояний DFA. Каждое состояние в строящемся DFA соответствует некоторому подмножеству состояний NFA. Для текущего подмножества состояний (субсета) рассматриваются все возможные входные символы алфавита — и для каждого символа вычисляется новое подмножество состояний NFA, достижимых из текущего субсета. Эти новые подмножества становятся новыми состояниями DFA.

Определение функций перехода. Переход из одного состояния DFA в другое по конкретному символу определяется как объединение всех состояний NFA, в которые можно попасть из текущего подмножества состояний по этому символу (с учётом возможных ε‑переходов).

Завершение построения. Процесс продолжается до тех пор, пока не будут обработаны все вновь полученные состояния DFA — то есть пока не останется непосещённых субсетов. В итоге получается DFA, эквивалентный исходному NFA: каждое его состояние кодирует некоторую комбинацию состояний NFA, что гарантирует охват всех возможных путей вычислений.
Таким образом, данный алгоритм демонстрирует, что для любого NFA существует эквивалентный ему DFA.
